
task: detect # (str) YOLO task, i.e. detect, segment, classify, pose, obb
mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

model: 
  type: yolov8n # (str) model type or model file, i.e. yolov8n, yolov8s, yolov8m, yolov8l, yolov8x, yolov8n-seg, yolov8s-seg, yolov8m-seg, yolov8l-seg, yolov8x-seg, yolov8n-pose, yolov8s-pose, yolov8m-pose, yolov8l-pose, yolov8x-pose
  num_classes: 80 # (int) number of classes for custom model, i.e. 80 for COCO, 1 for custom
  
runtime:
  save: True # (bool) save train checkpoints and predict results
  save_dir: res/detect/train # (str) path to save results, i.e. runs/detect/train
  device: 0 # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
  batch: 16 # (int) number of images per batch (-1 for AutoBatch)
  workers: 8 # (int) number of worker threads for data loading (per RANK if DDP)
  imgsz: 640 # (int | list) input images size as int for train and val modes, or list[h,w] for predict and export modes
  randomness:
    deterministic: True # (bool) whether to enable deterministic mode
    seed: 0 # (int) random seed for reproducibility
  train:
    epochs: 2 # (int) number of epochs to train for
    patience: 2 # (int) epochs to wait for no observable improvement for early stopping of training
    save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)
    close_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)
    resume: False # (bool) resume training from last checkpoint
    amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
    warmup_epochs: 3.0 # (float) warmup epochs (fractions ok)
  val:
    conf: 0.2 # (float) confidence threshold for validation, i.e. 0.001
    iou: 0.5 # (float) intersection over union (IoU) threshold for NMS
    max_det: 300 # (int) maximum number of detections per image
  predict:
    source: # (str, optional) source directory for images or videos
    visualize: False # (bool) visualize model features
  export:
    format: onnx # (str) format to export to
    int8: False # (bool) CoreML/TF INT8 quantization
    dynamic: False # (bool) ONNX/TF/TensorRT: dynamic axes
    simplify: True # (bool) ONNX: simplify model using `onnxslim`
    opset: # (int, optional) ONNX: opset version

augmentation:
  augment: True # (bool) whether to use data augmentation
  hsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)
  hsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)
  hsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)
  degrees: 0.0 # (float) image rotation (+/- deg)
  translate: 0.1 # (float) image translation (+/- fraction)
  scale: 0.5 # (float) image scale (+/- gain)
  shear: 0.0 # (float) image shear (+/- deg)
  perspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001
  flipud: 0.0 # (float) image flip up-down (probability)
  fliplr: 0.5 # (float) image flip left-right (probability)
  bgr: 0.0 # (float) image channel BGR (probability)
  mosaic: 1.0 # (float) image mosaic (probability)
  mixup: 0.0 # (float) image mixup (probability)
  copy_paste: 0.0 # (float) segment copy-paste (probability)
  copy_paste_mode: "flip" # (str) the method to do copy_paste augmentation (flip, mixup)

data:
  type: custom # (str) path to data file, i.e. coco8, i.e. coco8 or custom 
  path: ./coco8 # dataset root dir
  train: images/train # train images (relative to 'path') 4 images
  val: images/val # val images (relative to 'path') 4 images
  test: # test images (optional)
  names:
    0: person
    1: bicycle
    2: car
    3: motorcycle
    4: airplane
    5: bus
    6: train
    7: truck
    8: boat
    9: traffic light
    10: fire hydrant
    11: stop sign
    12: parking meter
    13: bench
    14: bird
    15: cat
    16: dog
    17: horse
    18: sheep
    19: cow
    20: elephant
    21: bear
    22: zebra
    23: giraffe
    24: backpack
    25: umbrella
    26: handbag
    27: tie
    28: suitcase
    29: frisbee
    30: skis
    31: snowboard
    32: sports ball
    33: kite
    34: baseball bat
    35: baseball glove
    36: skateboard
    37: surfboard
    38: tennis racket
    39: bottle
    40: wine glass
    41: cup
    42: fork
    43: knife
    44: spoon
    45: bowl
    46: banana
    47: apple
    48: sandwich
    49: orange
    50: broccoli
    51: carrot
    52: hot dog
    53: pizza
    54: donut
    55: cake
    56: chair
    57: couch
    58: potted plant
    59: bed
    60: dining table
    61: toilet
    62: tv
    63: laptop
    64: mouse
    65: remote
    66: keyboard
    67: cell phone
    68: microwave
    69: oven
    70: toaster
    71: sink
    72: refrigerator
    73: book
    74: clock
    75: vase
    76: scissors
    77: teddy bear
    78: hair drier
    79: toothbrush

optimizer:
  type: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
  nbs: 64 # (int) nominal batch size
  weight_decay: 0.0005 # (float) optimizer weight decay 5e-4
  lr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
  momentum: 0.937 # (float) SGD momentum/Adam beta1
  warmup_momentum: 0.8
  warmup_bias_lr: 0.1

scheduler:
  lrf: 0.01 # (float) final learning rate (lr0 * lrf)
  cos_lr: False # (bool) use cosine learning rate scheduler

loss:
  box: 7.5 # (float) box loss gain, i.e. 7.5
  cls: 0.5 # (float) class loss gain, i.e. 0.5
  dfl: 1.5 # (float) distribution focal loss gain, i.e. 1.5
  pose: 12.0 # (float) pose loss gain, i.e. 12.0
  kobj: 1.0 # (float) keypoint objectness loss gain, i.e. 1.0


# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]